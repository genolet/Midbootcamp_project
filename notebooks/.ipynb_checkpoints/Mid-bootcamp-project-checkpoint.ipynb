{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61981068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import sklearn\n",
    "import shap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "pd.set_option('display.max_columns', None) \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as st\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6596829",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_raw = pd.read_csv('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/data/raw/listings2.csv')\n",
    "display(listings_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4335b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will remove the columns that I think wont be relevant for the model\n",
    "\n",
    "listings = listings_raw.drop([\"listing_url\", \"scrape_id\", \"host_url\", \"host_location\",\n",
    "                         \"host_thumbnail_url\", \"host_neighbourhood\", \"host_listings_count\",\n",
    "                         \"neighborhood_overview\", \"minimum_minimum_nights\",\n",
    "                         \"maximum_minimum_nights\", \"minimum_maximum_nights\", \"maximum_maximum_nights\",\n",
    "                         \"minimum_nights_avg_ntm\", \"maximum_nights_avg_ntm\", \n",
    "                         \"description\", \"host_about\", \"has_availability\", \"availability_30\", \n",
    "                         \"availability_60\", \"availability_90\", \"availability_365\",\n",
    "                         \"picture_url\", \"host_picture_url\", \"last_scraped\",\n",
    "                         \"name\", \"host_id\", \"host_name\", \"host_since\",\n",
    "                         \"host_has_profile_pic\", \"calendar_last_scraped\",\n",
    "                         \"number_of_reviews_ltm\", \"number_of_reviews_l30d\",\n",
    "                         \"first_review\", \"last_review\", \"calculated_host_listings_count_entire_homes\",\n",
    "                         \"calculated_host_listings_count_private_rooms\", \"calculated_host_listings_count_shared_rooms\",\n",
    "                         \"host_total_listings_count\", \"host_identity_verified\", \"latitude\",\n",
    "                         \"longitude\", \"maximum_nights\", \"minimum_nights\",\n",
    "                         \"calculated_host_listings_count\", \"number_of_reviews\"], axis = 1)\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now I will check for missing values \n",
    "\n",
    "listings.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ad78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will remove the following columns since they contain too many missing values\n",
    "### and will also probably wont be too relevant for the model\n",
    "\n",
    "listings = listings.drop([\"host_response_time\", \"host_response_rate\", \"neighbourhood\",\n",
    "                         \"bathrooms\", \"calendar_updated\", \"license\", \"host_acceptance_rate\",\n",
    "                         \"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\", \n",
    "                          \"review_scores_location\", \"review_scores_value\", \"reviews_per_month\"], axis = 1)\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debdde90",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will drop the Nas of these columns, since the number is not so big\n",
    "\n",
    "listings = listings.dropna(subset=[\"host_is_superhost\", \"bathrooms_text\", \"bedrooms\", \"beds\"])\n",
    "print(listings.isna().sum())\n",
    "print(listings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf3b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now I will take a look a the column types\n",
    "\n",
    "listings.info()\n",
    "\n",
    "### Clearly, it seems \"price\" needs to be cleaned, also, the number of bathrooms should be an interger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now I will take a closer look at the columns to clean them \n",
    "### I will first clean the column \"bathrooms_text\"\n",
    "\n",
    "listings[\"bathrooms_text\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bath(x):\n",
    "    if \"shared\" in x:\n",
    "        return 0\n",
    "    if re.match('\\d{1}.\\d{1}', x):\n",
    "        y = re.findall('\\d{1}.\\d{1}', x)\n",
    "        return y[0]\n",
    "    if re.match('\\d{1}', x):\n",
    "        y = re.findall('\\d{1}', x)\n",
    "        return y[0]\n",
    "    else:\n",
    "        return \"0.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings[\"bathrooms_text\"] = list(map(clean_bath, listings[\"bathrooms_text\"]))\n",
    "listings[\"bathrooms_text\"] = pd.to_numeric(listings[\"bathrooms_text\"])\n",
    "listings[\"bathrooms_text\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings.rename(columns={'bathrooms_text': 'n_bathrooms'})\n",
    "listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now I will clean the column \"price\"\n",
    "\n",
    "listings[\"price\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(x):\n",
    "    y = \"\"\n",
    "    for char in x:\n",
    "        if char == \"$\":\n",
    "            pass\n",
    "        elif char == \",\":\n",
    "            pass\n",
    "        else:\n",
    "            y = y + char\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings[\"price\"] = list(map(clean_price, listings[\"price\"]))\n",
    "listings[\"price\"] = pd.to_numeric(listings[\"price\"])\n",
    "listings[\"price\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98de02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now I want to extract some features from the column \"ammenities\" to see whether \n",
    "### they would add an extra value to the property\n",
    "\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "listings[[\"amenities\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930cdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('max_colwidth', 10)\n",
    "pd.reset_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ammenities_wifi(row):\n",
    "    if \"Wifi\" in row[\"amenities\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ammenities_kitchen(row):\n",
    "    if \"Kitchen\" in row[\"amenities\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ammenities_parking(row):\n",
    "    if \"parking\" in row[\"amenities\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ammenities_balcony(row):\n",
    "    if \"balcony\" in row[\"amenities\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17884b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ammenities_bbq(row):\n",
    "    if \"BBQ grill\" in row[\"amenities\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ammenities_washer(row):\n",
    "    if \"Washer\" in row[\"amenities\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\"wifi\":clean_ammenities_wifi, \"kitchen\":clean_ammenities_kitchen, \n",
    "            \"parking\":clean_ammenities_parking, \"balcony\":clean_ammenities_balcony,\n",
    "            \"bbq\":clean_ammenities_bbq, \"washer\":clean_ammenities_washer}\n",
    "\n",
    "for key,value in function.items():\n",
    "    listings[key] = listings.apply(value, axis = 1)\n",
    "    \n",
    "listings = listings.drop([\"amenities\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now I want to extract features from the column host_verifications\n",
    "\n",
    "listings[\"host_verifications\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hostverification_email(row):\n",
    "    if \"email\" in row[\"host_verifications\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebf81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hostverification_phone(row):\n",
    "    if \"phone\" in row[\"host_verifications\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab787fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hostverification_work_email(row):\n",
    "    if \"work_email\" in row[\"host_verifications\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function = {\"host_email\":clean_hostverification_email, \"host_phone\":clean_hostverification_phone, \n",
    "            \"host_work_email\":clean_hostverification_work_email}\n",
    "\n",
    "for key,value in function.items():\n",
    "    listings[key] = listings.apply(value, axis = 1)\n",
    "    \n",
    "listings = listings.drop([\"host_verifications\"], axis = 1)\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I want to filter out the rows of neighbourhood_cleansed column that have less that 30\n",
    "### values \n",
    "\n",
    "listings[\"neighbourhood_cleansed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf96472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nc(row):\n",
    "    lst = list(listings[\"neighbourhood_cleansed\"].value_counts().loc[lambda x : x>30].to_frame().reset_index()[\"index\"])\n",
    "    if row[\"neighbourhood_cleansed\"] in lst:\n",
    "        return row[\"neighbourhood_cleansed\"]\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac226094",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings[\"neighbourhood_cleansed\"] = listings.apply(clean_nc, axis = 1)\n",
    "listings[\"neighbourhood_cleansed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8469b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I also want to filter out the rows of property_type column that have less that 30\n",
    "### values \n",
    "\n",
    "listings[\"property_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a17238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pt(row):\n",
    "    lst = list(listings[\"property_type\"].value_counts().loc[lambda x : x>30].to_frame().reset_index()[\"index\"])\n",
    "    if row[\"property_type\"] in lst:\n",
    "        return row[\"property_type\"]\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ea0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings[\"property_type\"] = listings.apply(clean_pt, axis = 1)\n",
    "listings[\"property_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb304b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now I want to see whether there is any relaitionship between the categorical columns \n",
    "### \"neighbourhood_cleansed\" and \"property_type\" have too many values and will generate NAs, so\n",
    "### I will not do the test with them \n",
    "\n",
    "cols1 = [\"neighbourhood_group_cleansed\"]\n",
    "cols2 = [\"room_type\", \n",
    "       \"instant_bookable\", \"host_is_superhost\"]\n",
    "for col1 in cols1:\n",
    "    for col2 in cols2:\n",
    "        x1 = listings.groupby([col1, col2]).agg({col2:\"count\"})\n",
    "        x1.columns = [\"Count\"]\n",
    "        x1 = x1.reset_index()\n",
    "        x1 = x1.pivot(index=col1,columns=col2).reset_index()\n",
    "        display(x1)\n",
    "        x1 = x1.iloc[:,1:]\n",
    "        print(\"Chi2 test for\", col1, \"vs\", col2, \"is:\", st.chi2_contingency(x1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = [\"room_type\"]\n",
    "cols2 = [\"neighbourhood_group_cleansed\", \n",
    "       \"instant_bookable\", \"host_is_superhost\"]\n",
    "for col1 in cols1:\n",
    "    for col2 in cols2:\n",
    "        x1 = listings.groupby([col1, col2]).agg({col2:\"count\"})\n",
    "        x1.columns = [\"Count\"]\n",
    "        x1 = x1.reset_index()\n",
    "        x1 = x1.pivot(index=col1,columns=col2).reset_index()\n",
    "        display(x1)\n",
    "        x1 = x1.iloc[:,1:]\n",
    "        print(\"Chi2 test for\", col1, \"vs\", col2, \"is:\", st.chi2_contingency(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = [\"instant_bookable\"]\n",
    "cols2 = [\"neighbourhood_group_cleansed\", \"room_type\",\n",
    "       \"host_is_superhost\"]\n",
    "for col1 in cols1:\n",
    "    for col2 in cols2:\n",
    "        x1 = listings.groupby([col1, col2]).agg({col2:\"count\"})\n",
    "        x1.columns = [\"Count\"]\n",
    "        x1 = x1.reset_index()\n",
    "        x1 = x1.pivot(index=col1,columns=col2).reset_index()\n",
    "        display(x1)\n",
    "        x1 = x1.iloc[:,1:]\n",
    "        print(\"Chi2 test for\", col1, \"vs\", col2, \"is:\", st.chi2_contingency(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34448da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = [\"host_is_superhost\"]\n",
    "cols2 = [\"neighbourhood_group_cleansed\", \"room_type\",\n",
    "       \"instant_bookable\"]\n",
    "for col1 in cols1:\n",
    "    for col2 in cols2:\n",
    "        x1 = listings.groupby([col1, col2]).agg({col2:\"count\"})\n",
    "        x1.columns = [\"Count\"]\n",
    "        x1 = x1.reset_index()\n",
    "        x1 = x1.pivot(index=col1,columns=col2).reset_index()\n",
    "        display(x1)\n",
    "        x1 = x1.iloc[:,1:]\n",
    "        print(\"Chi2 test for\", col1, \"vs\", col2, \"is:\", st.chi2_contingency(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928610dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### It seems that column neighbourhood_group_cleansed is dependent on cols instant_bookable and host_is_superhost\n",
    "### Room_type is dependent on instant_bookable and host_is_superhost\n",
    "### I will look at the distribution of price in these categories and eliminate the cols where\n",
    "### I dont see much change\n",
    "\n",
    "cols = [\"room_type\", \"instant_bookable\", \"host_is_superhost\", \"neighbourhood_group_cleansed\"]\n",
    "for col in cols:\n",
    "    sns.histplot(x= \"price\", data = listings, hue =col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will then eliminate instant_bookable and host_is_superhost \n",
    "\n",
    "listings = listings.drop([\"instant_bookable\", \"host_is_superhost\"], axis = 1)\n",
    "listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will check whether there are any outliers in the \"price\" column\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=[5, 5])\n",
    "sns.boxplot(listings[\"price\"], color = \"dodgerblue\")\n",
    "\n",
    "### I will remove extreme outliers for the price column, which the model then wont be able to \n",
    "### predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings[listings[\"price\"] <= 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccee886",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will eliminate the rows where the n_bathrooms > 4, because all of these have only \n",
    "### one or two rows, which doesnt serve the model\n",
    "\n",
    "print(listings[\"n_bathrooms\"].value_counts())\n",
    "listings = listings[listings[\"n_bathrooms\"] <= 4.0]\n",
    "listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d4228",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will also eliminate the rows where the bedrooms > 7, because all of these have only \n",
    "### one or two rows, which doesnt serve the model\n",
    "\n",
    "print(listings[\"bedrooms\"].value_counts())\n",
    "listings = listings[listings[\"bedrooms\"] <= 7.0]\n",
    "listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings.rename(columns={'neighbourhood_cleansed': 'neighbourhood',\n",
    "                                   'neighbourhood_group_cleansed': 'district'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0059aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will export a csv file with the cleaned data, plus longitude and latitude for the \n",
    "### visualization of the datapoints\n",
    "\n",
    "coordinates = listings_raw[[\"id\", \"longitude\", \"latitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8757bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_clean = pd.merge(\n",
    "    left=listings, \n",
    "    right=coordinates, \n",
    "    on='id',\n",
    "    how='inner'\n",
    ")\n",
    "#listings_clean.to_csv('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/data/clean/listings_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7fc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will transform the \"district\", \"neighbourhood\", \n",
    "### \"property_type\" and \"room_type\" into ordinal columns \n",
    "\n",
    "cols = [\"neighbourhood\", \"district\", \"property_type\", \"room_type\"]\n",
    "\n",
    "for col in cols:\n",
    "    df = listings.groupby([col]).agg({\"price\":\"median\"}).reset_index()\n",
    "    df[\"value\"] = df[\"price\"]/df[\"price\"].min()\n",
    "    df = df[[col,\"value\"]]\n",
    "    dict_df = dict(df.values)\n",
    "    print(dict_df)\n",
    "    listings[col] = listings[col].map(dict_df)\n",
    "    print(listings[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f09c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in listings.columns:\n",
    "    sns.set_style(\"ticks\")\n",
    "    fig, ax = plt.subplots(figsize=[5, 5])\n",
    "    sns.histplot(listings[col], color = \"dodgerblue\")\n",
    "    filename = '{}.png'.format(col)\n",
    "    plt.savefig('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/images/'+filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "### The price column is heavily skewed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = listings[[\"price\", \"neighbourhood\", \"district\",\n",
    "                  \"accommodates\", \"n_bathrooms\", \"bedrooms\", \"beds\", \"room_type\",\n",
    "                   \"property_type\"]].corr()\n",
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings.drop([\"beds\"], axis = 1)\n",
    "listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bed6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = listings[[\"price\", \"neighbourhood\", \"district\",\n",
    "                  \"accommodates\", \"n_bathrooms\", \"bedrooms\", \"room_type\", \"property_type\"]].corr()\n",
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.savefig('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/images/corr_plot.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = listings.drop([\"id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8252540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X,y split\n",
    "\n",
    "y = listings[\"price\"]\n",
    "x = listings.drop([\"price\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train-test split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 85)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b32411",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalization\n",
    "\n",
    "transformer = MinMaxScaler().fit(x_train)\n",
    "\n",
    "with open(\"../scalers/min_max_scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(transformer, file)\n",
    "\n",
    "x_train_norm = transformer.transform(x_train)\n",
    "x_test_norm = transformer.transform(x_test)\n",
    "x_train_norm = pd.DataFrame(x_train_norm, columns=x_train.columns, index=x_train.index)\n",
    "x_test_norm = pd.DataFrame(x_test_norm, columns=x_test.columns, index=x_test.index)\n",
    "x_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The data from the price column is heavily skewed. I will therefore apply a log \n",
    "### transformation on the y_test and y_train data\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=[5, 5])\n",
    "sns.distplot(y_train, color = \"dodgerblue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee234c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log transformation\n",
    "\n",
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=[5, 5])\n",
    "sns.distplot(y_train_log, color='dodgerblue')\n",
    "plt.savefig('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/images/price_log.png', bbox_inches='tight')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016de8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear regression model with log y_test and y_train\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train, y_train_log)\n",
    "\n",
    "with open(\"../models/lm.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lm, file)\n",
    "\n",
    "y_pred_test = lm.predict(x_test)\n",
    "y_pred_train = lm.predict(x_train)\n",
    "r2_train = r2_score(np.exp(y_train_log), np.exp(y_pred_train))\n",
    "mse_train = mean_squared_error(np.exp(y_train_log), np.exp(y_pred_train))\n",
    "mae_train = mean_absolute_error(np.exp(y_train_log), np.exp(y_pred_train))\n",
    "mape_train = mean_absolute_percentage_error(np.exp(y_train_log), np.exp(y_pred_train))\n",
    "print(\"r2 train:\", r2_train)\n",
    "print(\"mse train:\", mse_train)\n",
    "print(\"mae train:\", mae_train)\n",
    "print(\"mape train:\", mape_train)\n",
    "r2_test = r2_score(np.exp(y_test_log), np.exp(y_pred_test))\n",
    "mse_test = mean_squared_error(np.exp(y_test_log), np.exp(y_pred_test))\n",
    "mae_test = mean_absolute_error(np.exp(y_test_log), np.exp(y_pred_test))\n",
    "mape_test = mean_absolute_percentage_error(np.exp(y_test_log), np.exp(y_pred_test))\n",
    "print(\"r2 test:\", r2_test)\n",
    "print(\"mse test:\", mse_test)\n",
    "print(\"mae test:\", mae_test)\n",
    "print(\"mape test:\", mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e8c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_relevance = list(zip(np.abs(lm.coef_), x_train_norm.columns, lm.coef_))\n",
    "column_relevance.sort(reverse=True)\n",
    "column_relevance = [(item[1],item[-1],item[0]) for item in column_relevance]\n",
    "column_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=[5, 5])\n",
    "sns.scatterplot(np.exp(y_pred_test), y_test, color = \"dodgerblue\")\n",
    "plt.xlabel('y_pred_test')\n",
    "plt.ylabel('y_test')\n",
    "plt.savefig('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/images/test_pred.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_test - np.exp(y_pred_test)\n",
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=[5, 5])\n",
    "sns.histplot(error, color='dodgerblue', element=\"step\", fill=False)\n",
    "plt.xlabel('y_test - y_pred_test')\n",
    "plt.savefig('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/images/error_png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(lm, x_train)\n",
    "shap_values = explainer(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef56d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=[5, 5])\n",
    "shap.plots.beeswarm(shap_values, max_display=20, show=False)\n",
    "plt.savefig('/Users/origenolet/Desktop/Ironhack/Week5/Mid-bootcamp-project/images/shap.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b0ff65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
